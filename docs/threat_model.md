# Threat Model (Fairness Scope)

**Scope:** measurement of group outcome disparities in NLP/LLM outputs and AR/VR annotation datasets.

- Inputs: model predictions (0/1), protected group labels
- Risks: disparate impact, unequal error rates
- Out-of-scope: adversarial prompt attacks, PII leakage (this starter focuses on fairness only)
